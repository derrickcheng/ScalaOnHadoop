"".	4
"*"	10
"alice,bob	10
"console"	1
"hadoop.root.logger".	1
"jks".	4
#	94
#*.sink.ganglia.dmax=jvm.metrics.threadsBlocked=70,jvm.metrics.memHeapUsedM=40	1
#*.sink.ganglia.slope=jvm.metrics.gcCount=zero,jvm.metrics.memHeapUsedM=both	1
#Default	1
#Security	1
#datanode.sink.file.filename=datanode-metrics.out	1
#datanode.sink.ganglia.servers=yourgangliahost_1:8649,yourgangliahost_2:8649	1
#jobtracker.sink.file.filename=jobtracker-metrics.out	1
#jobtracker.sink.ganglia.servers=yourgangliahost_1:8649,yourgangliahost_2:8649	1
#log4j.appender.DRFA.MaxBackupIndex=30	1
#log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601}	1
#log4j.appender.RFA.File=${hadoop.log.dir}/${hadoop.log.file}	1
#log4j.appender.RFA.MaxBackupIndex=30	1
#log4j.appender.RFA.MaxFileSize=1MB	1
#log4j.appender.RFA.layout.ConversionPattern=%d{ISO8601}	2
#log4j.appender.RFA.layout=org.apache.log4j.PatternLayout	1
#log4j.appender.RFA=org.apache.log4j.RollingFileAppender	1
#log4j.logger.org.apache.hadoop.fs.FSNamesystem=DEBUG	1
#log4j.logger.org.apache.hadoop.mapred.JobTracker=DEBUG	1
#log4j.logger.org.apache.hadoop.mapred.TaskTracker=DEBUG	1
#maptask.sink.file.filename=maptask-metrics.out	1
#maptask.sink.ganglia.servers=yourgangliahost_1:8649,yourgangliahost_2:8649	1
#namenode.sink.file.filename=namenode-metrics.out	1
#namenode.sink.ganglia.servers=yourgangliahost_1:8649,yourgangliahost_2:8649	1
#new	1
#reducetask.sink.file.filename=reducetask-metrics.out	1
#reducetask.sink.ganglia.servers=yourgangliahost_1:8649,yourgangliahost_2:8649	1
#tasktracker.sink.file.filename=tasktracker-metrics.out	1
#tasktracker.sink.ganglia.servers=yourgangliahost_1:8649,yourgangliahost_2:8649	1
$HADOOP_BALANCER_OPTS"	1
$HADOOP_DATANODE_OPTS"	1
$HADOOP_HOME/conf/slaves	1
$HADOOP_HOME/logs	1
$HADOOP_JOBTRACKER_OPTS"	1
$HADOOP_NAMENODE_OPTS"	1
$HADOOP_SECONDARYNAMENODE_OPTS"	1
$USER	1
%-5p	3
%c:	3
%c{2}	3
%c{2}:	2
%m%n	8
%p	5
'	2
'(i.e.	2
'*',	2
'default'	2
'man	1
(%F:%M(%L))	2
(fs,	1
(maximum-system-jobs	2
*	2
*.sink.file.class=org.apache.hadoop.metrics2.sink.FileSink	1
*.sink.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30	1
*.sink.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31	1
*.sink.ganglia.period=10	1
*.sink.ganglia.supportsparse=true	1
,	2
-	3
-->	14
-1	1
-o	1
/tmp	1
100	1
1000.	1
25%	1
25.	1
3.0	1
3.1	1
30-day	2
33%	1
4	1
50%	1
<!--	14
</allocations>	1
</body>	1
</configuration>	8
</description>	33
</html>	1
</property>	43
</table>	1
</tr>	2
</value>	2
</xsl:for-each>	1
</xsl:stylesheet>	1
</xsl:template>	1
<?xml	10
<?xml-stylesheet	7
<allocations>	1
<body>	1
<configuration>	8
<description>	4
<description>ACL	10
<description>If	2
<description>Keystore	2
<description>Maximum	1
<description>Must	2
<description>Number	1
<description>Optional.	8
<description>Percentage	1
<description>The	10
<description>Truststore	2
<html>	1
<name>mapred.capacity-scheduler.default-init-accept-jobs-factor</name>	1
<name>mapred.capacity-scheduler.default-maximum-active-tasks-per-queue</name>	1
<name>mapred.capacity-scheduler.default-maximum-active-tasks-per-user</name>	1
<name>mapred.capacity-scheduler.default-minimum-user-limit-percent</name>	1
<name>mapred.capacity-scheduler.default-supports-priority</name>	1
<name>mapred.capacity-scheduler.default-user-limit-factor</name>	1
<name>mapred.capacity-scheduler.init-poll-interval</name>	1
<name>mapred.capacity-scheduler.init-worker-threads</name>	1
<name>mapred.capacity-scheduler.maximum-system-jobs</name>	1
<name>mapred.capacity-scheduler.queue.default.capacity</name>	1
<name>mapred.capacity-scheduler.queue.default.init-accept-jobs-factor</name>	1
<name>mapred.capacity-scheduler.queue.default.maximum-capacity</name>	1
<name>mapred.capacity-scheduler.queue.default.maximum-initialized-active-tasks-per-user</name>	1
<name>mapred.capacity-scheduler.queue.default.maximum-initialized-active-tasks</name>	1
<name>mapred.capacity-scheduler.queue.default.minimum-user-limit-percent</name>	1
<name>mapred.capacity-scheduler.queue.default.supports-priority</name>	1
<name>mapred.capacity-scheduler.queue.default.user-limit-factor</name>	1
<name>mapred.queue.default.acl-administer-jobs</name>	1
<name>mapred.queue.default.acl-submit-job</name>	1
<name>security.admin.operations.protocol.acl</name>	1
<name>security.client.datanode.protocol.acl</name>	1
<name>security.client.protocol.acl</name>	1
<name>security.datanode.protocol.acl</name>	1
<name>security.inter.datanode.protocol.acl</name>	1
<name>security.inter.tracker.protocol.acl</name>	1
<name>security.job.submission.protocol.acl</name>	1
<name>security.namenode.protocol.acl</name>	1
<name>security.refresh.policy.protocol.acl</name>	1
<name>security.task.umbilical.protocol.acl</name>	1
<name>ssl.client.keystore.keypassword</name>	1
<name>ssl.client.keystore.location</name>	1
<name>ssl.client.keystore.password</name>	1
<name>ssl.client.keystore.type</name>	1
<name>ssl.client.truststore.location</name>	1
<name>ssl.client.truststore.password</name>	1
<name>ssl.client.truststore.type</name>	1
<name>ssl.server.keystore.keypassword</name>	1
<name>ssl.server.keystore.location</name>	1
<name>ssl.server.keystore.password</name>	1
<name>ssl.server.keystore.type</name>	1
<name>ssl.server.truststore.location</name>	1
<name>ssl.server.truststore.password</name>	1
<name>ssl.server.truststore.type</name>	1
<property>	43
<table	1
<td><a	1
<td><xsl:value-of	2
<td>description</td>	1
<td>name</td>	1
<td>value</td>	1
<tr>	2
<value>	2
<value>*</value>	10
<value>-1</value>	1
<value>100000</value>	2
<value>100</value>	3
<value>10</value>	2
<value>1</value>	2
<value>200000</value>	2
<value>3000</value>	1
<value>5000</value>	1
<value>5</value>	1
<value></value>	10
<value>false</value>	2
<value>jks</value>	4
<xsl:for-each	1
<xsl:output	1
<xsl:stylesheet	1
<xsl:template	1
A	12
ACL	13
Add	1
AdminOperationsProtocol,	1
All	2
Appender	7
Audit	1
Below	1
By	1
CLASSPATH	1
Capacity	2
CapacityScheduler.	1
ClientDatanodeProtocol,	1
ClientProtocol,	1
Comma	2
Command	1
ConnectTimeout=1	1
Counter	1
Custom	1
DN.	2
Daily	1
DatanodeProtocol,	1
Date	1
Debugging	1
Default	10
Define	2
DistributedFileSystem.	1
Each	1
Empty	2
Event	1
EventCounter	1
Extra	3
FSNamesystem	1
Fair	2
File	3
For	13
Ganglia	3
HADOOP_BALANCER_OPTS="-Dcom.sun.management.jmxremote	1
HADOOP_CLASSPATH=	1
HADOOP_CLIENT_OPTS	1
HADOOP_DATANODE_OPTS="-Dcom.sun.management.jmxremote	1
HADOOP_HEAPSIZE=2000	1
HADOOP_IDENT_STRING=$USER	1
HADOOP_JOBTRACKER_OPTS="-Dcom.sun.management.jmxremote	1
HADOOP_LOG_DIR=${HADOOP_HOME}/logs	1
HADOOP_MASTER=master:/home/$USER/src/hadoop	1
HADOOP_NAMENODE_OPTS="-Dcom.sun.management.jmxremote	1
HADOOP_NICENESS=10	1
HADOOP_OPTS	1
HADOOP_OPTS=-server	1
HADOOP_PID_DIR=/var/hadoop/pids	1
HADOOP_SECONDARYNAMENODE_OPTS="-Dcom.sun.management.jmxremote	1
HADOOP_SLAVES=${HADOOP_HOME}/conf/slaves	1
HADOOP_SLAVE_SLEEP=0.1	1
HADOOP_SSH_OPTS="-o	1
HADOOP_TASKTRACKER_OPTS=	1
HH:mm:ss}	2
Hadoop	1
Hadoop-specific	1
Hadoop.	1
INFO	1
If	9
Initialization	2
InterDatanodeProtocol,	1
InterTrackerProtocol,	1
Irrespective	2
It	3
Its	1
JAVA_HOME	1
JAVA_HOME.	1
JAVA_HOME=/System/Library/Frameworks/JavaVM.framework/Versions/1.6.0/	1
Java	2
Jets3t	1
Job	3
JobSubmissionProtocol,	1
JobTracker.	1
LogLevel	1
LogMessage	1
Logfile	1
LoggerName	1
Logging	2
MB.	1
Map/Reduce	2
Metrics.	1
Must	4
NN	2
NamenodeProtocol,	1
Null	1
Once	4
One	1
Optional.	1
Pattern	2
Put	4
RefreshAuthorizationPolicyProtocol,	1
Required.	1
Rolling	2
Rollver	1
Scheduler	1
Scheduler.	1
Seconds	1
See	2
SendEnv=HADOOP_CONF_DIR"	1
Sends	1
Set	1
Should	1
So	1
Summary	2
TaskLog	1
TaskUmbilicalProtocol,	1
The	35
This	7
Threshold	1
Trap	1
Unset	2
Use	1
When	1
Where	1
With	1
You	1
[prefix].[source|sink|jmx].[instance].[options]	1
a	51
above	3
absence	1
absolute	1
accepted	2
accordingly.	1
account	2
acls	1
acquire	1
across	4
added	1
administrators	2
affected.	1
after	1
all	21
allocated	1
allocations	1
allow	1
allowed	6
allowed.</description>	10
also	1
amount	3
and	36
any	2
appended	1
appender	1
applied	1
applies	1
appropriate	1
are	26
arrive	1
as,	1
assigned.	1
at	7
audit	2
authorization	2
available	1
backup	1
backups	1
based	1
be	36
before	1
being	1
best	1
between	2
beyond	1
blank.	12
block	1
border="1">	1
by	42
can	23
cannot	1
capacity	8
capacity.	1
certain	2
change.	1
client	1
client-to-datanode	1
clients	3
cluster	6
cluster's	1
cluster,	1
cluster.	2
clusters,	1
code	2
comma	1
comma-separated	10
commands	3
commands.	1
communciate	1
communicate	4
competition	1
complete	1
concurrently,	1
concurrently.	5
config	1
configuration	7
configuration,	2
configuration.	1
configure	1
configured	3
console	1
consume	1
contains	1
convention,such	1
correctly	1
could	2
counts	1
curtail	1
daemon	1
daily:	1
datanodes	1
decisions	1
decisions.	1
default	9
default,	1
default.	9
defined	2
defines	1
depends	1
details	1
details,	1
determine	3
dfs,	1
dfsadmin	1
different	1
directory	1
disk.	4
distcp	1
distcp.	2
distributed	1
do	4
documentation	2
don't	1
e.g.	12
e.g.,	1
elements.	1
enabled	2
enforces	1
environment	2
equal	3
etc)	1
etc.	1
events	1
example,	1
exceed	4
excess	1
explained	1
export	19
false	1
faster	1
file	4
file,	1
file.	5
files	2
follow	1
following	2
for	31
format	2
format:	1
former	1
from	1
from.	1
fsck,	1
generation	1
get	2
given	2
greater	2
group	25
group1,group2.	2
guarantees	1
hadoop	2
hadoop.	1
hadoop.log.dir.	1
hadoop.log.dir=#configured	1
hadoop.log.dir=.	1
hadoop.log.file=hadoop.log	1
hadoop.mapreduce.jobsummary.log.file	1
hadoop.mapreduce.jobsummary.log.file=hadoop-mapreduce.jobsummary.log	1
hadoop.mapreduce.jobsummary.logger=${hadoop.root.logger}	1
hadoop.mapreduce.jobsummary.logger=INFO,JSA	1
hadoop.metrics.log.level=INFO	1
hadoop.root.logger=INFO,console	1
hadoop.security.log.file=SecurityAuth.audit	1
hadoop.tasklog.iscleanup=false	1
hadoop.tasklog.logsRetainHours=12	1
hadoop.tasklog.noKeepSplits=4	1
hadoop.tasklog.purgeLogSplits=true	1
hadoop.tasklog.taskid=null	1
hadoop.tasklog.totalLogFileSize=100	1
have	3
heap	1
here.	1
his/her	1
host:path	1
hosts.	1
how	1
href="configuration.xsl"?>	7
http://hadoop.apache.org/common/docs/r0.20.205.0/fair_scheduler.html.	1
if	5
implementation	1
implies	2
important	1
imposed.	1
in	31
in-effect.	1
includes	1
increase	1
initialize	2
initialize.	1
initialized	4
initialized,	1
instance	1
inter-datanode	1
into	2
irrespective	1
is	54
it	4
its	1
java	1
job	11
job's	1
job,	1
jobs	23
jobs,	1
jobs.	3
jobtracker	1
jobtracker.	1
kill	2
large	2
latter	1
lead	1
lesser	1
level	1
levels	2
library	1
like	2
limit	8
limit.	1
limited	1
limits	1
list	27
localhost	2
log	1
log4j.additivity.org.apache.hadoop.mapred.JobInProgress$JobSummary=false	1
log4j.appender.DRFA.DatePattern=.yyyy-MM-dd	1
log4j.appender.DRFA.File=${hadoop.log.dir}/${hadoop.log.file}	1
log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601}	1
log4j.appender.DRFA.layout=org.apache.log4j.PatternLayout	1
log4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppender	1
log4j.appender.DRFAS.File=${hadoop.log.dir}/${hadoop.security.log.file}	1
log4j.appender.DRFAS.layout.ConversionPattern=%d{ISO8601}	1
log4j.appender.DRFAS.layout=org.apache.log4j.PatternLayout	1
log4j.appender.DRFAS=org.apache.log4j.DailyRollingFileAppender	1
log4j.appender.EventCounter=org.apache.hadoop.log.metrics.EventCounter	1
log4j.appender.JSA.DatePattern=.yyyy-MM-dd	1
log4j.appender.JSA.File=${hadoop.log.dir}/${hadoop.mapreduce.jobsummary.log.file}	1
log4j.appender.JSA.layout.ConversionPattern=%d{yy/MM/dd	1
log4j.appender.JSA.layout=org.apache.log4j.PatternLayout	1
log4j.appender.JSA=org.apache.log4j.DailyRollingFileAppender	1
log4j.appender.NullAppender=org.apache.log4j.varia.NullAppender	1
log4j.appender.TLA.isCleanup=${hadoop.tasklog.iscleanup}	1
log4j.appender.TLA.layout.ConversionPattern=%d{ISO8601}	1
log4j.appender.TLA.layout=org.apache.log4j.PatternLayout	1
log4j.appender.TLA.taskId=${hadoop.tasklog.taskid}	1
log4j.appender.TLA.totalLogFileSize=${hadoop.tasklog.totalLogFileSize}	1
log4j.appender.TLA=org.apache.hadoop.mapred.TaskLogAppender	1
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd	1
log4j.appender.console.layout=org.apache.log4j.PatternLayout	1
log4j.appender.console.target=System.err	1
log4j.appender.console=org.apache.log4j.ConsoleAppender	1
log4j.logger.SecurityLogger.additivity=false	1
log4j.logger.SecurityLogger=OFF,console	1
log4j.logger.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=WARN	1
log4j.logger.org.apache.hadoop.mapred.JobInProgress$JobSummary=${hadoop.mapreduce.jobsummary.logger}	1
log4j.logger.org.apache.hadoop.metrics2=${hadoop.metrics.log.level}	1
log4j.logger.org.jets3t.service.impl.rest.httpclient.RestS3Service=ERROR	1
log4j.rootLogger=${hadoop.root.logger},	1
log4j.threshhold=ALL	1
logged	1
logger	4
logging	2
long	1
manager	1
map	1
mapred.acls.enabled	2
mapred.capacity-scheduler.queue.<queue-name>.property-name.	1
mapred.local.dir.	1
mapred.local.dir=#configured	1
mapred.tasktracker.tasks.sleeptime-before-sigkill=#sleep	1
mapreduce.cluster.administrators	2
mapreduce.tasktracker.group.	1
mapreduce.tasktracker.group=#configured	1
master	1
match="configuration">	1
max	2
maximum	6
maximum-capacity	3
means	13
mentioned	1
messages	1
method="html"/>	1
metrics	1
midnight	1
miliseconds	1
minimum	2
modify	1
more	6
mradmin	1
mradmins	1
much	1
multipe	2
multiple	3
name="{name}"><xsl:value-of	1
namenode	1
namenode.	2
names	2
names.	10
naming	2
nature	1
nice'.	1
no	8
nodes	2
nodes.	1
note	1
number	14
occupying	1
of	74
on	11
only	4
operation.	2
operations	2
optional.	1
options	1
options.	2
or	4
org.apache.hadoop.metrics2	1
other	1
others	1
otherwise	1
overridden	1
overrides	4
owner	1
package.html	1
parameters	2
parent	1
particular	2
paths.	1
per-user,	2
percentage	4
pid	1
point	1
policy	1
poll	1
poller	1
pool	1
pre-emption,	1
priorities	2
priority	2
process	1
processes.	1
properties	3
property	12
protocol	3
provides	1
querying	1
queue	12
queue's	3
queue,	5
queue-capacity	1
queue-capacity)	2
queue.	6
queued	4
queues	6
queues.	3
racks	1
recovery.	1
reduce	1
refresh	2
related	1
remote	2
representing	1
required	1
resource	1
resources	2
resources.	3
rolled	1
root	1
rootlogger	1
rsync'd	1
rsyncs	1
running	2
runtime	1
sample	1
scheduler	2
scheduler.	2
scheduling	4
secondary	1
seconds	1
security	2
select="description"/></td>	1
select="name"/></a></td>	1
select="property">	1
select="value"/></td>	1
send	1
sending	1
sent	1
sent.	1
separate	1
separated	15
service	1
set	8
setting	2
settings	1
severity	1
should	1
side	1
sig	1
sigterm	1
single	5
site-specific	4
size	1
slave	3
sleep	1
slots	2
slots.	1
so	2
some	1
space),	2
special	12
specific	1
specified	1
specified.	6
ssh	1
started	2
status	1
stored.	2
string	1
submission,	1
submit	4
submits	1
submitted	2
summary	1
support	2
supportsparse	1
suppose	1
syntax:	1
system	3
taken	2
task	1
tasks	3
tasks,	2
tasktracker.	1
tasktrackers	1
template	1
terms	1
than	6
that	6
the	85
them.	2
then	3
there	2
they	4
thing	1
third	1
this	19
thread	2
threads	2
time	3
time,	1
timestamp.	1
to	62
true,	2
true.	2
two	1
type="text/xsl"	7
updating	1
use	6
use,	1
use.	2
used	19
useful	1
user	40
user's	4
user1,user2	2
users	14
users,	1
users,wheel".	10
value	26
value.	2
values	3
variable	1
variables	1
various	1
vary	1
version="1.0">	1
version="1.0"?>	10
via	3
view	1
want	1
when	1
where	2
where,	1
which	17
who	3
will	8
with	5
worker	1
would	7
xmlns:xsl="http://www.w3.org/1999/XSL/Transform"	1
you	1
